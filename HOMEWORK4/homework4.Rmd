---
title: "Homework4"
author: "Carlotta Porcelli - exam_ID 62"
date: "6/13/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# PART 1

## Question 1A: Merge the ChIP peaks that overlap over 1bp or more. How many merged regions are produced compared to how many peaks you started with?

In order to run the _bedtools merge_, the _txnCHIP.bed_ file needs to be sorted. This is done by chromosome and then by start position.

```{bash, echo=TRUE, eval=FALSE}
sort -k1,1 -k2,2n txnChIP.bed > sorted_txnCHIP.bed # presort of .bed file
```

```{bash, echo=TRUE, eval=FALSE}
wc -l txnChIP.bed 
```
The length of the _txnCHIP.bed_ file is: 4380444.

Merging the _txnCHIP.bed_ file is done not only merging the intervals but also reporting the number of intervals that were integrated into the new file using the __-c 1__ (applying _option_ on first column) and __-o count__ parameters. 
```{bash, echo=TRUE, eval=FALSE}
bedtools merge -i sorted_txnCHIP.bed -c 1 -o count > count_merged_sorted_txnCHIP.bed
```

```{bash, echo=TRUE, eval=FALSE}
wc -l count_merged_sorted_txnCHIP.bed
```
The merge tool produced 746610 regions, with a difference of 3633834 regions compared to the initial peaks number. 

## Question 1B: Plot the distribution of ChIP peaks in each merged region. Briefly comment your plot.
```{r, echo=TRUE, warning=FALSE}
library("ggplot2")
CHIP_peaks <- read.table("count_merged_sorted_txnCHIP.bed", header = F)
CHIP_distribution <- ggplot(data=CHIP_peaks, aes(V4)) + 
            geom_bar(stat="bin", color='black', fill='grey', binwidth = 0.2) +
            scale_x_continuous(trans='log2') +
            xlab("log2-scaled merged regions") +
            ylab("Counts") +
            ggtitle("Distribution of CHIP peaks in merged regions") +
            theme(plot.title = element_text(hjust = 0.5))
CHIP_distribution
```

The plot shows that more than 3e+05 of the merged regions are composed of only one site. The number of merged regions decrease drastically with the increase of overlapping regions.

## Question 1C: Using R, produce a new BED file that contains the 10 merged regions having the highest number of ChIP peaks.
```{r, echo=TRUE}
top_10 <- as.data.frame(CHIP_peaks[order(-CHIP_peaks$V4),][0:10,])
write.table(top_10, file='top_10_CHIP_peaks.bed', quote = F, row.names = F, col.names = F)
```

## Question 1D: Upload this into the UCSC browser. Look at each merged region and try to interpret it, also taking the peaks it contains into account. What do the merged regions typically overlap? Is there a particular factor that is responsible for the clusters?
Once the top_10 CHIP peaks BED file has been uploaded on the UCSC browser, the track has been mapped to the hg19 assembly.
![Screenshots of the 10 merged regions with the highest number of ChIP peaks]

All of the merged regions overlap the RNA polymerase II subunit __POLR2A__. The __POLR2A__ forms the largest subunit of RNA polymerase II, enzyme responsible for synthesizing messenger RNA in eukaryotes. In addition, this subunit forms the DNA binding domain of the polymerase, a groove in which the DNA template is transcribed into RNA.[Reference: ](https://www.ncbi.nlm.nih.gov/gene/5430). The transcription factors binding sites are clustered because of the presence of __POLR2A__ and its repeatedly presence. 

## Question 1E: What could we have done to improve the analysis? 
To improve the analysis the merge function could be set to combine regions that overlap for more than one basepair. This constraint would produce less overlapping regions. 

# PART 2

## Question 2.1: Provide one line of code which will make symbolic links only to the 6 fastq files.
```{bash, eval=F, echo=T}
ln -s /home/bohta/HW4/part2/*.fastq /home/qbp693/
```

## Question 2.2: Check how well the sequencing run went - Use the 'wc' function to calculate the number of reads in all fastq files and comment on the results.
```{bash, eval=F, echo=T}
grep '^+$' -c *.fastq # counts the number of lines starting and ending with '+' sign
```
The count of reads for each file is: WT1_R1.fastq:45626717, WT1_R2.fastq:45626717, WT2_R1.fastq:41428670, WT2_R2.fastq:41428670, WT3_R1.fastq:19326183, WT3_R2.fastq:19326183
It is noticeable that there is no difference in number of reads between the strands R1 and R2 of the same library. This is because the two files come from the same cDNA sequence and they have probably been trimmed before removing the orphan reads.

## Question 2.3: 
### A) Report the command for running Kallisto on the WT1 RNA-seq data.
```{bash, echo=T, eval=F}
nice /home/bohta/bin/kallisto quant --index /home/bohta/HW4/part2/kallistoIndex 
    --fr-stranded -t 6 --plaintext --bias -o kallisto_out/ WT1_R1.fastq WT1_R2.fastq
```

### B) Report the number of pseudo-aligned reads.
The number of pseudo-aligned reads is 23720001.

### C*) Report the estimated average fragment length. Based on this result, what is then the distance between the 3' ends of the two reads in an average read pair?
The estimated average fragment length is 178.486. 
```{bash, echo=T, eval=FALSE}
cat WT1_R1.fastq | awk '{if(NR%4==2) print length($1)}' > input_readslength_R1.txt
cat WT1_R2.fastq | awk '{if(NR%4==2) print length($1)}' > input_readslength_R2.txt
```

```{r, echo=TRUE, eval=FALSE}
read_len_R1 <- read.table('input_readslength_R1.txt', header=F) # R1 reads length
read_len_R2 <- read.table('input_readslength_R2.txt', header=F) # R2 reads length
r1_mean <- mean(read_len_R1$V1) # average length of R1 reads
r2_mean <- mean(read_len_R2$V1) # average length of R2 reads
avg_fragment_length <- 178.486 
abs(avg_fragment_length - (r1_mean+r2_mean)) # computes the absolute distance between 3' ends
```
The resulting fragment from the computation is a transcript compatible with the mapped reads, this means that the distance between the two 3' ends of a read pair can be computed as the absolute difference between the average_fragment_length and the average length of the reads in R1 and R2.
This results in an average distance between the 3' ends of an average read pair of almost 18 bases.

## Question 2.4: 
### A*) Report the command for running Salmon on the WT1 RNA-seq data.
```{bash, eval=F, echo=T}
nice /home/bohta/bin/salmon quant --index /home/bohta/HW4/part2/salmonIndex -p 6 
  --libType A --seqBias --gcBias -1 WT1_R1.fastq -2 WT1_R2.fastq -o salmon_out/
```

### B) Report the most likely library type as identify by Salmon.
The automatically detected most likely library is ISF.

### C) Report mapping rate.
The mapping rate = 60.9567%.

## Question 2.5: Which tool aligned more reads? Comment on the result.
Salmon aligned 27812554 reads, with almost 61% of mapped reads whereas Kallisto mapped almost 52% . Kallisto is based on pseudoalignments to _compatible transcripts_, Salmon is based on lightweight alignments, chains of maximal and super maximal exact matches. Both of the tools mapped above 50% which can be considerated as a good result but surely Salmon performed better.

## Question 2.6: 
### A) Compare the estimated 'effective length' of the isoform 'TCONS_00000020' from Kallisto and Salmon to each other and the reference length. 
```{r, echo=TRUE, eval=T}
kallisto_quant <- read.table('abundance.tsv', header=T)
salmon_quant <- read.table('quant.sf', header=T)
e_len_kal <- kallisto_quant[kallisto_quant$target_id=='TCONS_00000020',]
e_len_salmon <- salmon_quant[salmon_quant$Name == 'TCONS_00000020',]
e_len_kal
e_len_salmon
```


### B) What could explain the difference in the effective length? Which estimate do you trust more?

The effective lengths will be affected by the estimated empirical fragment length distribution, the method of calculating effective lengths and whether or not bias correction is used. The most trustworthy is the Salmon computation because it corrects not only the for sequence-specific biases but also for the fragment-level GC biases. Moreover it is unlikely that the effective length is larger than the actual length as Kallisto shows.

# PART 3
## Question 3.1: Load the data into R. How many isoforms are quantified in the count data? 
```{r, echo=TRUE, eval=TRUE}
part3_data <- load('part3.Rdata')
nrow(countDF)
```
The number of isoforms quantified in the count data is: 5787.

## Question 3.2: Report the R code for how to calculate RPKM values.
```{r, echo=TRUE, eval=TRUE}
library_size <- colSums(countDF) # number of reads mapped
transcript_lenghts <- c(annotationDF$length) # vector of lengths of transcripts
# calculation of RPKM values
Rpkm_values <-  as.data.frame(t(t(countDF) * 1000000 / library_size) * 
                                as.vector(1000 / transcript_lenghts))
head(Rpkm_values, 2)
```

## Question 3.3: Make a one-liner (without the use of ';') that outputs the mean RPKM value of each sample. The restrictions from the previous question no longer apply.
```{r, echo=TRUE, eval=TRUE, warning=FALSE}
mean_values <- cbind(rowMeans(Rpkm_values[,0:3]), rowMeans(Rpkm_values[,4:6]))
colnames(mean_values)<- c('K samples means', 'S samples means')
head(mean_values, 3)
```


## Question 3.4: Make histograms of the distribution of the logRpkm expression values. 
```{r, echo=TRUE, eval=TRUE}
library("ggplot2")
trans_log <- data.frame(t(logRpkmDF))
# trans_log$tool_label <- 
# 
# logRpkm_plot <- ggplot(data=logRpkmDF, aes(logRpkmDF[])) + 
#             geom_histogram(stat="bin", color='black', fill='grey', binwidth = 0.2) +
#             xlab("log10-transformed filtered RPKM") +
#             ylab("Frequency") +
#             ggtitle("Distribution of CHIP peaks in merged regions") +
#             theme(plot.title = element_text(hjust = 0.5)) 
#     #         scale_fill_manual(values =
#     # c("K_WT1_RPKM", 'K_WT2_RPKM', 'K_WT3_RPKM' = "darkblue", "S_WT1_RPKM", 'S_WT1_RPKM', 'S_WT1_RPKM' = "red"))+
#     #         facet_wrap(~KnockDownTarget)
# logRpkm_distribution

```


## Question 3.5: For each tool use logRpkm to calculate all pairwise replicate Pearson correlations of the replicate expression values and report the numbers in a table (one table per tool). 

## Question 3.6: 
### A)	Construct a function which calculates the CV and use the apply() function to calculate the CV based on logRpkm values for Kallisto and Salmon (separately). 1p

### B)	Plot the distribution of CV values as density lines (in one single plot) using color to indicate the tool and log transform the x-axis (using log10). 1p

### C)	Comment on the CV plots using max 75 words. 2p


## Question 3.7: Based on all the results you have collected here (all of part 2 and all of part 3), discuss in max 100 words which tool would you choose to continue with if you wanted to make a differential expression analysis.


# PART 4
```{r, echo=TRUE, eval=TRUE}
set.seed(2017)
library(ggplot2)
library(GGally)
```

## Question 1: Read both the expression matrix ("ExpressionMatrix.tab") and study design ("StudyDesign.tab") into R. Report the number of samples and the number of genes.
```{r, echo=TRUE, eval=TRUE}
expression_m <- read.table('ExpressionMatrix.tab', header=T) # data import
study_design <- read.table('StudyDesign.tab', header=T) # data import
samples_number <- ncol(expression_m)
samples_number
gene_number <- nrow(expression_m)
gene_number
```
In the data set there are 75 samples and 10000 genes.

## Question 2: Perform PCA on the samples and report the amount of variance contained in the first 5 principle components.
```{r, echo=TRUE, eval=TRUE}
expression_m_transposed <- t(expression_m) # transposition of the matrix
pca_genes <- prcomp(expression_m_transposed, center = T, scale. = T) # pca
```
The expression values have been scaled using center and scale arguments set to TRUE in order to normalize the data. The amount of variance in the first 5 principal components is: PC1:0.05092, PC2:0.03281,  PC3:0.02097, PC4:0.01877, PC5:0.01525.

## Question 3: Make a plot of PC1 vs PC2, where knock down efficiency is indicated by color and knock down target is indicated by shape. Comment on the plot. 
```{r, echo=TRUE, eval=TRUE}
library(ggplot2)
library(GGally)
gene_plot <- data.frame(pca_genes$x, study_design) 
ggplot(data=gene_plot, aes(PC1, PC2, color=KnockDownEfficiency, shape = KnockDownTarget)) + 
  geom_point(size=1.5)+
  ggtitle('PCA of first 2 principal components') +
  theme(plot.title = element_text(hjust = 0.5))
    
```
The plot shows a clearly separated cluster of control genes with knock down efficiency equals to zero. The majority of Gene A samples seem to have a knock down efficiency between 0.50 and 1 on the other end there are three outliers closer to the control cluster with efficiency closer to zero. The samples from the Gene B are well clustered on the right side of the control targets and they span the entire range of efficiency values.  

## Question 4: Perform a K-means clustering of the data, using k=3 and 10 random starting points. Visualize the clustering by making a plot of PC1 vs PC2, where the clusters are indicated by color. Briefly comment on how the clustering corresponds to the known knockdown targets.
```{r, echo=TRUE, eval=TRUE}
k3_means <- kmeans(expression_m_transposed, centers=3, nstart = 10) # 3-means with 10 starting points
gene_plot$cluster <- factor(k3_means$cluster) # adding clusters to data frame
# plotting results
k_means_plot <- ggplot(data=gene_plot, aes(x=PC1, y=PC2, color=cluster, shape = KnockDownTarget)) + 
  geom_point(size=1.5) +
  ggtitle('PC1 and PC2 3k-means clustered of gene expression') +
  theme(plot.title = element_text(hjust = 0.5))
k_means_plot
```

The plot shows that the middle cluster contains datapoints with knock down efficiency closer to zero. This cluster should contain only control samples so it is evident that something in the experiment didn't work as expected. The cluster on the right side groups all the samples of Gene B and the other cluster on the left contains all the samples from Gene A with higher knock down efficiencies. 

## Question 5: Using a maximum number of 3 plots, investigate whether there is any truth to the postdoc allegations: Can you see a difference in samples prepared by Alice and Bob? Is there any indication Bob has ruined a sample? Discuss you results using a maximum of 75 words. 
```{r, echo=TRUE, eval=TRUE, warning=FALSE}
KD_effiency <- ggplot(data=study_design,
            aes(KnockDownEfficiency, fill=PostDoc)) + 
            geom_bar(stat="bin", binwidth = 0.5, position=position_dodge()) +
            scale_fill_manual(values = c("Bob" = "darkblue", "Alice" = "red"))+
            xlab("KnockDown efficiency") +
            ylab("Counts") +
            ggtitle("Genes knockdown efficiency") +
            theme(plot.title = element_text(hjust = 0.5))+
            facet_wrap(~KnockDownTarget)
KD_effiency
k_means_plot + geom_text(aes(label=PostDoc), size=3, hjust=-0.25, vjust=-0.8)

distances <- dist(study_design$KnockDownEfficiency)
distance_tree <- hclust(distances)
plot(distance_tree, label=study_design$PostDoc, 
     col = "#487AA1", col.axis = "#F38630",
     main='Distances tree')

```


## Question 6: Based on all you observations in Question 1-5, discuss whether the experiment is still useful, or whether the postdocs have ruined it. Use a maximum of 100 words. 3p


# PART 5

## Question 1: Read the DE analysis ('DifferentialExpression.tab) results into R, and show the first few lines of the file. 
```{r, echo=TRUE, eval=TRUE}
differential_expression <- read.table('DifferentialExpression.tab', header=T)
head(differential_expression, 3)
```


## Question 2: As part of a single plot, produce two MA-plots (one for each knockdown). To mitigate overplotting, points on the plot should be transparent
```{r, echo=T, eval=TRUE}
library(ggplot2)
library(GGally)
library(gridExtra)

ma_plot <- ggplot(data = differential_expression) + 
  geom_point(aes(meanExpression, A.logFC), size=1.5, alpha=0.07) +
  geom_hline(yintercept = 0, col='red')+
  ggtitle("Ma-plot for Gene A") +
  ylim(-7,7)+
  theme(plot.title = element_text(hjust = 0.5))

mb_plot <- ggplot(data = differential_expression) + 
  geom_point(aes(meanExpression, B.logFC), size=1.5, alpha=0.07) +
  geom_hline(yintercept = 0, col='red') +
  ggtitle("Ma-plot for Gene B") +
  ylim(-7,7)+
  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(ma_plot, mb_plot, nrow=1, ncol=2)

```


## Question 3: Explain how an MA-plot can be used to investigate whether expression data has been properly normalized (max 75 words). 

## Question 4: Report the number of upregulated and downregulated genes that are significantly DE after correction for multiple testing (at alpha=0.05). Which knockdown target has the highest total number of DE genes? 
```{r, echo=TRUE, eval=TRUE}
de_genes <- differential_expression[which(differential_expression$A.FDR<0.05 & differential_expression$B.FDR<0.05),]
down_reg_a <- nrow(de_genes[de_genes$A.logFC<0,])
down_reg_a
up_reg_a <- nrow(de_genes[de_genes$A.logFC>0,])
up_reg_a

down_reg_b <- nrow(de_genes[de_genes$B.logFC<0,])
down_reg_b
up_reg_b <- nrow(de_genes[de_genes$B.logFC>0,])
up_reg_b
```



## Question 5: Plot the two sets of logFCs  (log2 fold changes) against each other. Color points based on whether they are significantly DE after multiple testing correction (at alpha=0.05) in either one or both of the knockdowns. 3p

## Question 6: Calculate the Pearson correlation between the logFCs of the two knockdowns, and test whether this correlation is significant. 2p

## Question 7: Caroline asks you to construct a 2-by-2 contingency table showing whether genes are significantly DE (after correcting for multiple testing, alpha=0.05) in the two knockdowns. Perform a Fisher???s Exact test for any association between the DE genes in the two knockdowns. 3p

## Question 8: Based on Question 4-7, do you think the geneA and geneB transcription factors regulate the same genes? Use a maximum of 100 words.


